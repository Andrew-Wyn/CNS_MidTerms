{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RNN for Character Recognition\n",
        "\n",
        "## Libraries and Utilities"
      ],
      "metadata": {
        "id": "LSZ6iljGRHCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5KzrNK7J6qD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import random\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature =1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds)/temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(1,preds,1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "def generate_text(model, text, maxlen, generationlen):\n",
        "  #select a text seed at random\n",
        "  start_index = random.randint(0,len(text)-maxlen -1)\n",
        "  generated_text = text[start_index:start_index+maxlen]\n",
        "  print(' --- Generating text with seed:\"' + generated_text + '\"')\n",
        "\n",
        "  #tries a range of different temperatures\n",
        "  for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
        "    print('----temperature:', temperature)\n",
        "    sys.stdout.write(generated_text)\n",
        "\n",
        "    #generates characters starting from the seed text\n",
        "    for i in range(generationlen):\n",
        "\n",
        "      #one-hot encodes the characters generated so far\n",
        "      sampled = np.zeros((1,maxlen,len(chars)))\n",
        "      for t, char in enumerate(generated_text):\n",
        "        sampled[0, t, char_indices[char]] = 1.\n",
        "      \n",
        "      #samples the next character\n",
        "      preds = model.predict(sampled, verbose = 0)[0]\n",
        "      next_index = sample(preds, temperature)\n",
        "      next_char = chars[next_index]\n",
        "      \n",
        "      #appends the newly generated character \n",
        "      generated_text += next_char\n",
        "      generated_text = generated_text[1:]\n",
        "\n",
        "      sys.stdout.write(next_char)\n",
        "    sys.stdout.write('\\n\\n')\n"
      ],
      "metadata": {
        "id": "_vjVaUnTVTBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the data\n",
        "\n",
        "here I chose to use as source text **Anarchism and Socialism**, by George Plechanoff\n",
        "\n",
        "\n",
        "https://www.gutenberg.org/files/30506/30506.txt"
      ],
      "metadata": {
        "id": "AKWyeHrLRqiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = keras.utils.get_file(\n",
        "    '305068.txt',\n",
        "    origin = 'https://www.gutenberg.org/files/30506/30506.txt'\n",
        ")\n",
        "\n",
        "text = open(path).read().lower()\n",
        "\n",
        "text = text[12425 + 270 + 13:500000]\n",
        "\n",
        "print('corpus length:', len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWmfuaHFSv4C",
        "outputId": "019e39fe-b168-4142-fdf5-a28826635fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/30506/30506.txt\n",
            "227067/227067 [==============================] - 0s 1us/step\n",
            "corpus length: 210387\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 100 character of the manuscript\n",
        "print(text[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvr7LjUfTqME",
        "outputId": "8f1d2482-b9a8-4423-b04b-0fb4ea36cf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anarchism and socialism\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "chapter i\n",
            "\n",
            "the point of view of the utopian socialists\n",
            "\n",
            "\n",
            "the french mate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 100 #length of the extracted sequences for training\n",
        "step = 1 #we sample a sequence every step characters\n",
        "\n",
        "\n",
        "sentences = [] #this will hold the extracted sequences\n",
        "next_chars = [] #this will hold the target charcters (the follow-up characters)\n",
        "for i in range(0, len(text)-maxlen, step):\n",
        "  sentences.append(text[i:i+maxlen])\n",
        "  next_chars.append(text[i+maxlen])\n",
        "\n",
        "print('Number of sequences:', len(sentences))\n",
        "\n",
        "chars = sorted(list(set(text))) #list of unique characters in the corpus\n",
        "print('Unique characters:', len(chars))\n",
        "#create a dictionary that maps unique characters to their index in the list \"chars\"\n",
        "char_indices = dict((char,chars.index(char)) for char in chars)\n",
        "\n",
        "print('Vectorization...', end = '')\n",
        "#we (one-hot-)encode the charcters into binary arrays \n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype = bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype = bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "  y[i,char_indices[next_chars[i]]] = 1\n",
        "print('completed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P714iKsSUnif",
        "outputId": "657b0dc7-53ea-41a7-c6dc-41d2000ac911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sequences: 210287\n",
            "Unique characters: 58\n",
            "Vectorization...completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWtEDB0WU3Vv",
        "outputId": "c69bc846-902c-45d2-d104-945fc04de609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210287, 100, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqo-jIY2U6aV",
        "outputId": "c9deea35-9b86-4525-9d60-074761b5b760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(210287, 58)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model\n"
      ],
      "metadata": {
        "id": "bMH81apTU9ja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.LSTM(128, input_shape = (maxlen, len(chars))))\n",
        "model.add(keras.layers.Dense(len(chars), activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "#we use categorical crossentropy because the targets are one-hot encoded\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)"
      ],
      "metadata": {
        "id": "E1bYk3FZVA4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "7pVtbJdUVML3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,batch_size=1024, epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZm54xJcVNr6",
        "outputId": "7050463a-2893-43c8-cf5a-e656b721aecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "206/206 [==============================] - 13s 31ms/step - loss: 2.4336\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.8498\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 6s 30ms/step - loss: 1.6428\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.5344\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.4652\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.4169\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.3796\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.3483\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.3238\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.3026\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.2819\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.2670\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.2531\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.2416\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.2285\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.2179\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.2102\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.2021\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1941\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.1882\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1814\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 6s 31ms/step - loss: 1.1771\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1678\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 6s 32ms/step - loss: 1.1614\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1578\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1566\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1481\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 7s 32ms/step - loss: 1.1475\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 6s 32ms/step - loss: 1.1442\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 7s 33ms/step - loss: 1.1376\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09d7362d70>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Generate Text"
      ],
      "metadata": {
        "id": "_IpBJEuSVr3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model, text, maxlen, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6N6u-D7VufE",
        "outputId": "f3334149-086b-40d8-d558-807c0cae055b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --- Generating text with seed:\"premely\n",
            "ridiculous.\n",
            "\n",
            "\"anarchy means the negation of authority. now, government claims to base\n",
            "the le\"\n",
            "----temperature: 0.2\n",
            "premely\n",
            "ridiculous.\n",
            "\n",
            "\"anarchy means the negation of authority. now, government claims to base\n",
            "the least and the property of the \"propaganda of the results of the production of the \"contract\" price. the property of the production of the production of the proletariat is the product of the production of the production of the production of the anarchists all the property of the property of the works of the production of the property of the production of the property of the product of the property of the product of society of the property of the production of the reader of the production of the wor\n",
            "\n",
            "----temperature: 0.5\n",
            " the product of society of the property of the production of the reader of the production of the working organised in the especially them as they de l'allions and the proletariat is the production of his property in the social constitution. and, and therefore, and the has criticus of the social constitution of their state with the society of the social constitution of property will be a protested the political constitution of the proletariat is a very distribution of the articles of the \"constitution\" of humanity.\n",
            "\n",
            "the state is not as\n",
            "the property of the political organisation of the proudhon\n",
            "\n",
            "\n",
            "----temperature: 1.0\n",
            "ution\" of humanity.\n",
            "\n",
            "the state is not as\n",
            "the property of the political organisation of the proudhon\n",
            "begnaled\n",
            "this sells up\n",
            "the pholiserve an interest. this arrarity, but the profound the \"political men'nery.\"\n",
            "\n",
            "\"equality_. and he were are disachist? the material ridiculow, as geaver up all the very and individually no magision by consequence, to companditur, or this only who combeds became feffored quite even than fainch 17-259. they and so. \n",
            "to the same bourgeois\n",
            "reorganised by the utopy of vrouchody\n",
            "worts for the histordm a\n",
            "pass--what is shall only now the anarchists, so l'anciproptratious es\n",
            "\n",
            "----temperature: 1.2\n",
            "chody\n",
            "worts for the histordm a\n",
            "pass--what is shall only now the anarchists, so l'anciproptratious essential but states\n",
            "midialty after bakounine has\n",
            "stre diffolly about\n",
            "farthers; now lend that that is readon--where is all evolented\n",
            "in should be inilital one in\n",
            "this undistrymen, \"the anarchist clearly! id\n",
            "certal ego, understanding (unforatitatemed.\n",
            "by we have no loudly\n",
            "save this god, like the morality, libory\n",
            "sayh bohther political scienked winise their unle in benifory of im\n",
            "insifured, a\n",
            "distendion_\n",
            "nated, away d'ithelous; accorty,\" from the tribunalists,'\" _visaphicagious\" figght. (__regued \n",
            "t\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU Model"
      ],
      "metadata": {
        "id": "3fDIRapHYN_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = keras.models.Sequential()\n",
        "gru_model.add(keras.layers.GRU(128, input_shape = (maxlen, len(chars))))\n",
        "gru_model.add(keras.layers.Dense(len(chars), activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "#we use categorical crossentropy because the targets are one-hot encoded\n",
        "gru_model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)"
      ],
      "metadata": {
        "id": "r7z9GQVpYQlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "2-_u2jn_Y4ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.fit(x,y,batch_size=1024, epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8X_emwTY7E4",
        "outputId": "69d1ad59-ce8f-411a-b3ce-245669de5674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "206/206 [==============================] - 8s 28ms/step - loss: 2.2606\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.6826\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.5131\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.4350\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3873\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 6s 29ms/step - loss: 1.3598\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3384\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3208\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3106\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2972\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2883\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2821\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2753\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 6s 27ms/step - loss: 1.2732\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2674\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 6s 27ms/step - loss: 1.2741\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2664\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 6s 27ms/step - loss: 1.2589\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2585\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2668\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2790\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 6s 27ms/step - loss: 1.2588\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2574\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2810\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 6s 29ms/step - loss: 1.2720\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 6s 27ms/step - loss: 1.2563\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3900\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3595\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.3007\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 6s 28ms/step - loss: 1.2760\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09d64b8310>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU Generate Text"
      ],
      "metadata": {
        "id": "6JDos9GbZfJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(gru_model, text, maxlen, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQsOwFvfZhMU",
        "outputId": "8763ad3a-8c48-4da4-f4bd-980decff1d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --- Generating text with seed:\"mpetition with every possible system of fines,\n",
            "stoppages from wages, espionage, etc.; the workman ma\"\n",
            "----temperature: 0.2\n",
            "mpetition with every possible system of fines,\n",
            "stoppages from wages, espionage, etc.; the workman may contracting its even the state with the property, and it is the state and the state is the \"communist\" and the property of the social organisation of the property of the \"communist\" and the property\n",
            "\n",
            "----temperature: 0.5\n",
            "ist\" and the property of the social organisation of the property of the \"communist\" and the property in order to do with the proletarians in the production in the nature. the state, the property, a project gutenberg-tm license society the point of the learned the revolutions of the paper of the word\n",
            "\n",
            "----temperature: 1.0\n",
            "oject gutenberg-tm license society the point of the learned the revolutions of the paper of the word\n",
            "human nature. for anaties, \"the state. and abllen itselfing exchanications, stirner. but\n",
            "one menian from he fubllaie we know that seemed as the anarchist? heipretements bakounised.\n",
            "\n",
            "\n",
            "they over seinh \n",
            "\n",
            "----temperature: 1.2\n",
            " from he fubllaie we know that seemed as the anarchist? heipretements bakounised.\n",
            "\n",
            "\n",
            "they over seinh will his\n",
            "printice.\n",
            "\n",
            "[11]\n",
            "kropotkine, of the whole convinced to  sections comrisis: opprictioning turrers-\"as in insithel colly and pogethesto-plying his_ pledge, p. 3. goy, trothession out at rest pri\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Not Shallow RNN Model"
      ],
      "metadata": {
        "id": "dVthKDSuZbTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model = keras.models.Sequential()\n",
        "rnn_model.add(keras.layers.SimpleRNN(32, input_shape = (maxlen, len(chars)), return_sequences=True))\n",
        "rnn_model.add(keras.layers.SimpleRNN(64))\n",
        "rnn_model.add(keras.layers.Dense(len(chars), activation = 'softmax'))\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01)\n",
        "#we use categorical crossentropy because the targets are one-hot encoded\n",
        "rnn_model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)"
      ],
      "metadata": {
        "id": "qfC4FzUFZnNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "dag9x2k-Z38d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_model.fit(x,y,batch_size=1024, epochs = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AupdnBkZ5Rw",
        "outputId": "53616ffe-797e-4f6a-ec75-349b2f7a86a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "206/206 [==============================] - 41s 184ms/step - loss: 2.3987\n",
            "Epoch 2/30\n",
            "206/206 [==============================] - 38s 184ms/step - loss: 1.9413\n",
            "Epoch 3/30\n",
            "206/206 [==============================] - 39s 191ms/step - loss: 1.8110\n",
            "Epoch 4/30\n",
            "206/206 [==============================] - 38s 186ms/step - loss: 1.7447\n",
            "Epoch 5/30\n",
            "206/206 [==============================] - 38s 184ms/step - loss: 1.7076\n",
            "Epoch 6/30\n",
            "206/206 [==============================] - 37s 179ms/step - loss: 1.6781\n",
            "Epoch 7/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.6585\n",
            "Epoch 8/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.6465\n",
            "Epoch 9/30\n",
            "206/206 [==============================] - 38s 184ms/step - loss: 1.6337\n",
            "Epoch 10/30\n",
            "206/206 [==============================] - 37s 181ms/step - loss: 1.6258\n",
            "Epoch 11/30\n",
            "206/206 [==============================] - 37s 180ms/step - loss: 1.6201\n",
            "Epoch 12/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.6110\n",
            "Epoch 13/30\n",
            "206/206 [==============================] - 37s 182ms/step - loss: 1.6101\n",
            "Epoch 14/30\n",
            "206/206 [==============================] - 38s 182ms/step - loss: 1.6011\n",
            "Epoch 15/30\n",
            "206/206 [==============================] - 37s 180ms/step - loss: 1.5987\n",
            "Epoch 16/30\n",
            "206/206 [==============================] - 38s 184ms/step - loss: 1.5938\n",
            "Epoch 17/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.5906\n",
            "Epoch 18/30\n",
            "206/206 [==============================] - 37s 179ms/step - loss: 1.5891\n",
            "Epoch 19/30\n",
            "206/206 [==============================] - 38s 187ms/step - loss: 1.5859\n",
            "Epoch 20/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.5822\n",
            "Epoch 21/30\n",
            "206/206 [==============================] - 37s 181ms/step - loss: 1.5814\n",
            "Epoch 22/30\n",
            "206/206 [==============================] - 37s 181ms/step - loss: 1.5807\n",
            "Epoch 23/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.5788\n",
            "Epoch 24/30\n",
            "206/206 [==============================] - 37s 182ms/step - loss: 1.5760\n",
            "Epoch 25/30\n",
            "206/206 [==============================] - 37s 181ms/step - loss: 1.5714\n",
            "Epoch 26/30\n",
            "206/206 [==============================] - 38s 184ms/step - loss: 1.5751\n",
            "Epoch 27/30\n",
            "206/206 [==============================] - 37s 179ms/step - loss: 1.5736\n",
            "Epoch 28/30\n",
            "206/206 [==============================] - 37s 181ms/step - loss: 1.5734\n",
            "Epoch 29/30\n",
            "206/206 [==============================] - 37s 180ms/step - loss: 1.5708\n",
            "Epoch 30/30\n",
            "206/206 [==============================] - 38s 183ms/step - loss: 1.5717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f09d65c4fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Not Shallow RNN Generate Model"
      ],
      "metadata": {
        "id": "HZYmTgkdf3W8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(rnn_model, text, maxlen, 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9nCJkfYf6-r",
        "outputId": "bf52fafe-3d8f-45d1-a97a-788348f13507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " --- Generating text with seed:\"\n",
            "november, 1879. \"in 1881, in the month of september, when the dyers'\n",
            "strike broke out at villefranc\"\n",
            "----temperature: 0.2\n",
            "\n",
            "november, 1879. \"in 1881, in the month of september, when the dyers'\n",
            "strike broke out at villefrance and it is the state the social social common the socialist of the struggle of the social more a social common of the individualism of property of the struggle and the social social socialism of the \n",
            "\n",
            "----temperature: 0.5\n",
            "cial common of the individualism of property of the struggle and the social social socialism of the all the state is the person and the adrotes of the\n",
            "theorisation of society of the social organisation of society of the working minders site to the same in marx, of the peast of the enconotist and all\n",
            "\n",
            "----temperature: 1.0\n",
            "n of society of the working minders site to the same in marx, of the peast of the enconotist and all is ond the compantizin amnenks,\n",
            "fid the acios to\n",
            "work,! to babows; \"a mistiolonge. \n",
            "\"agek to probles, theme\n",
            "abook the governments \"the onty in mage, bendurie, opponstage is karely fe period is, and d\n",
            "\n",
            "----temperature: 1.2\n",
            "s, theme\n",
            "abook the governments \"the onty in mage, bendurie, opponstage is karely fe period is, and deterame;\"\n",
            "\n",
            "\n",
            "fooldeneg, of interalised,, social of rearriate, _ant you formol of pola, addays marible are krophers odim\n",
            "only binsclaights it. as the morall class maned rearend\n",
            "politicalignts heircal ca\n",
            "\n"
          ]
        }
      ]
    }
  ]
}